{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   label                                               text\n0      1  walking chelsea time day rather lovely love lo...\n1      0  first play night aaron rodgers int udfa cb bra...\n2      0  drove bike today miles felt like jim carrey irene\n3     -1  looking temp outside hpw get hotter sun goes f...\n4      0  rt redarmy therefore still expect arsenal sign...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>walking chelsea time day rather lovely love lo...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>first play night aaron rodgers int udfa cb bra...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>drove bike today miles felt like jim carrey irene</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1</td>\n      <td>looking temp outside hpw get hotter sun goes f...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>rt redarmy therefore still expect arsenal sign...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data Preparation\n",
    "\n",
    "import pandas as pd\n",
    "from preprocess import preprocess_text\n",
    "\n",
    "#loading the data\n",
    "train_set = pd.read_csv('semEval dataest/semeval-2017-train.csv', delimiter='\\t')\n",
    "test_set = pd.read_csv('semEval dataest/semeval-2017-test.csv', delimiter='\\t')\n",
    "dev_set = pd.read_csv('semEval dataest/semeval-2017-dev.csv', delimiter='\\t')\n",
    "\n",
    "#preprocessing the data\n",
    "train_set['text'] = train_set['text'].apply(preprocess_text)\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3b7e3466029445b79cca5108cf792ead"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\lenovo\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e08df8d8952642aab31e4e5c508ed1f1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFBertModel, BertTokenizer\n",
    "\n",
    "# Loading  BERT model architecture\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Loading BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Example\n",
    "input_text = \"Hello, how are you?\"\n",
    "input_ids = tokenizer.encode(input_text, add_special_tokens=True)\n",
    "inputs = tf.constant([input_ids])\n",
    "\n",
    "# Get BERT model outputs\n",
    "outputs = bert_model(inputs)\n",
    "outputs\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#Training the teacher model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize input data\n",
    "def tokenize_data(data, tokenizer, max_length):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for text in data['text']:\n",
    "        encoded_dict = tokenizer.encode_plus(text )\n",
    "\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "    return input_ids, attention_masks\n",
    "\n",
    "max_seq_length = 128\n",
    "num_labels = len(data['label'].unique())\n",
    "\n",
    "train_input_ids, train_attention_masks = tokenize_data(train_data, tokenizer, max_seq_length)\n",
    "val_input_ids, val_attention_masks = tokenize_data(val_data, tokenizer, max_seq_length)\n",
    "\n",
    "train_labels = torch.tensor(train_data['label'])\n",
    "val_labels = torch.tensor(val_data['label'])\n",
    "\n",
    "# Create DataLoader\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(val_input_ids, val_attention_masks, val_labels)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Define optimizer and training loop\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs = {\n",
    "            'input_ids': batch[0],\n",
    "            'attention_mask': batch[1],\n",
    "            'labels': batch[2]\n",
    "        }\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    val_accuracy = 0\n",
    "    val_loss = 0\n",
    "    for batch in val_dataloader:\n",
    "        inputs = {\n",
    "            'input_ids': batch[0],\n",
    "            'attention_mask': batch[1],\n",
    "            'labels': batch[2]\n",
    "        }\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            val_loss += outputs.loss.item()\n",
    "            logits = outputs.logits\n",
    "            preds = np.argmax(logits, axis=1)\n",
    "            val_accuracy += np.sum(preds == batch[2].numpy())\n",
    "\n",
    "    val_loss /= len(val_dataloader)\n",
    "    val_accuracy /= len(dev_set)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs}')\n",
    "    print(f'Val Loss: {val_loss:.4f} Val Acc: {val_accuracy:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}